{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "# used for loading or saving\n",
    "model_file = '/home/ramin/projects/ECO/src/python/modelbuilder/parsed_v3_valid.doc2vec'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4266193, 'sentences')\n"
     ]
    }
   ],
   "source": [
    "# 2 Build sentence list (each sentence needs at least 1 tag)\n",
    "filename = '/home/marcel/drive/data/eco/NAIL_DATAFIELD_txt/parsed_v3/parsed_v3_valid.txt'\n",
    "\n",
    "sentences = []\n",
    "from random import shuffle\n",
    "\n",
    "for uid, line in enumerate(open(filename)):\n",
    "    ls = gensim.models.doc2vec.LabeledSentence(words=line.split(), tags=['SENT_%s' % uid])\n",
    "    sentences.append(ls)\n",
    "print(len(sentences),'sentences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 3 Training the doc2vec model\n",
    "\n",
    "# tutorial https://rare-technologies.com/doc2vec-tutorial/\n",
    "# proposes shuffling or learning reate adjustment. we gonna do both\n",
    "# in total 20 epochs\n",
    "# took ca. 6.30 hours\n",
    "model = gensim.models.Doc2Vec(alpha=0.025, min_alpha=0.025)  # use fixed learning rate\n",
    "print('building vocab') \n",
    "model.build_vocab(sentences)\n",
    "\n",
    "base_alpha = model.alpha\n",
    "base_min_alpha = model.min_alpha\n",
    "\n",
    "for mepoch in range(2):\n",
    "    model.alpha = base_alpha \n",
    "    model.min_alpha = base_min_alpha\n",
    "    for epoch in range(10):\n",
    "        print('epoch',mepoch * 10 + epoch)\n",
    "        model.train(sentences)\n",
    "        model.alpha -= 0.002  # decrease the learning rate\n",
    "        model.min_alpha = model.alpha  # fix the learning rate, no decay\n",
    "    shuffle(sentences)\n",
    "\n",
    "# saving the model    \n",
    "model.save(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 4 Loading the model\n",
    "\n",
    "model_loaded = gensim.models.Doc2Vec.load(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 5 Test: printing sentence 9 and getting the most similar ones.\n",
    "test_sentence_index = 2639533\n",
    "\n",
    "print ' '.join(sentences[test_sentence_index][0])\n",
    "sims = model_loaded.docvecs.most_similar('SENT_'+str(test_sentence_index),topn = 30)\n",
    "print 'similar sentence',len(sims)\n",
    "print '\\nSIMILAR SENTENCES\\n'\n",
    "for sim in sims:\n",
    "    print nice_print(sim),sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 6 Tiny helper\n",
    "import re\n",
    "\n",
    "def print_word_list(wl):\n",
    "    str =  ' '.join(wl)\n",
    "    pattern = re.compile('\\s.\\s')\n",
    "    shift = 0\n",
    "    for ma in pattern.finditer(str):\n",
    "        str = str[:ma.start(0)-shift]+ma.group(0)[1:]+ str[ma.end(0)-shift:]\n",
    "        shift +=1\n",
    "    if str[-2] == ' ':\n",
    "        str = str[:-2] + str[-1:]\n",
    "    return str\n",
    "\n",
    "def nice_print(tagged_doc):\n",
    "    word_list = sentences[int(tagged_doc[0][5:])][0]\n",
    "    return print_word_list(word_list)\n",
    "\n",
    "def print_similar(similar):\n",
    "    return nice_print(similar)\n",
    "\n",
    "def nice_print_labSen(labeledSentence):\n",
    "    return print_word_list(labeledSentence[0])\n",
    "\n",
    "def print_index(index):\n",
    "    sentence = ' '.join(sentences[index][0])\n",
    "    return sentence\n",
    "    \n",
    "def get_similar_index(similar):\n",
    "    return int(similar[0][5:])\n",
    "       \n",
    "def get_index_tag(labeledSentence):\n",
    "    return labeledSentence[1][0]\n",
    "\n",
    "def get_index(labeledSentence):\n",
    "    return int(get_index_tag(labeledSentence)[5:])\n",
    "    \n",
    "def equal_word_lists(index1, index2):\n",
    "    wl1 = sentences[index1][0]\n",
    "    wl2 = sentences[index2][0]\n",
    "    if len(wl1) != len(wl2):\n",
    "        return False\n",
    "    else:\n",
    "        for i in range(len(wl1)):\n",
    "            if wl1[i] != wl2[i]:\n",
    "                return False\n",
    "    return True\n",
    "\n",
    "def get_lab_sent_by_similar(similar):\n",
    "    print get_similar_index(similar)\n",
    "    return sentences[get_similar_index(similar)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentence = sentences[124]\n",
    "\n",
    "print sentence\n",
    "sims = model_loaded.docvecs.most_similar(get_index_tag(sentence),topn = 10)\n",
    "print sims[0]\n",
    "print get_lab_sent_by_similar(sims[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 7 \n",
    "# iterate over similar sentences\n",
    "# needs the sentences loaded (cell 2)\n",
    "import random\n",
    "\n",
    "index = 1983\n",
    "# len(sentences)\n",
    "# print sentences[index]\n",
    "sentence = ' '.join(sentences[index][0])\n",
    "print sentence\n",
    "selected_indices = [index]\n",
    "\n",
    "for sentence in range(100):\n",
    "    sims = model_loaded.docvecs.most_similar('SENT_'+str(index))\n",
    "    while True:\n",
    "        selected = random.choice(sims)\n",
    "        check_index = int(selected[0][5:])\n",
    "        if check_index not in selected_indices:\n",
    "            break\n",
    "    index = check_index\n",
    "    selected_indices.append(index)\n",
    "    print nice_print(selected)\n",
    "#     print selected_indices\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print selected_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class LabSentTreeNode:\n",
    "    \n",
    "    def __init__(self, labeledSentence, parent = None):\n",
    "        self.sentence = labeledSentence\n",
    "#       self.sentence_index = sentence_index\n",
    "        self.similars = self.get_similars()  \n",
    "        self.randoms = []\n",
    "        self.children = {} # index: SentenceTreeNode\n",
    "        self.selected_child = -1 # None\n",
    "        self.parent = parent\n",
    "             \n",
    "    def get_similars(self):\n",
    "        return model_loaded.docvecs.most_similar(get_index_tag(self.sentence),topn = 10)\n",
    "    \n",
    "    def print_options(self):\n",
    "        for index, sentence in enumerate(self.similars):\n",
    "            print index, '(*)' if get_similar_index(sentence) in self.children else '', nice_print(sentence), sentence[1]\n",
    "        if self.parent:\n",
    "            print 'p', nice_print_labSen(self.parent.sentence)\n",
    "        print ':::RRR:::'\n",
    "        for index in range(10):\n",
    "            rnd_sen = sentences[random.randint(0,len(sentences))]\n",
    "            self.randoms.append(rnd_sen)\n",
    "            print 'r'+str(index),  nice_print_labSen(rnd_sen)\n",
    "            \n",
    "    def select_child(self):\n",
    "        u_input = raw_input('Next child: ')\n",
    "        if u_input == 'p':\n",
    "            u_input = -1\n",
    "        elif u_input == 'q':\n",
    "            u_input = -2\n",
    "        elif u_input.startswith('r'):\n",
    "            u_input = 100 + int(u_input[1:])\n",
    "        try:\n",
    "            selected_index = int(u_input)\n",
    "        except ValueError:\n",
    "            return self\n",
    "        if selected_index >= 0 and selected_index < len(self.similars):\n",
    "            lab_sent = get_lab_sent_by_similar(self.similars[selected_index])\n",
    "            child =  LabSentTreeNode(lab_sent, self)\n",
    "            self.children[selected_index] = child\n",
    "            self.selected_child = selected_index\n",
    "            return child\n",
    "        elif selected_index >= 100 and selected_index < len(self.randoms) + 100:\n",
    "            print 'random sen'\n",
    "            child =  LabSentTreeNode(self.randoms[selected_index - 100], self)\n",
    "            self.children[selected_index] = child\n",
    "            self.selected_child = selected_index    \n",
    "            return child\n",
    "        elif u_input == -1 and self.parent:\n",
    "            return self.parent\n",
    "        elif u_input == -2:\n",
    "            return None\n",
    "        \n",
    "    def toJSON(self):\n",
    "        return {'sentence':nice_print_labSen(self.sentence),\n",
    "                'index':get_index(self.sentence),\n",
    "               'children':[self.children[child_index].toJSON() for child_index in self.children]\n",
    "               }\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 8 \n",
    "# Story creator\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import json\n",
    "\n",
    "sentence = sentences[random.randint(0,len(sentences))]\n",
    "\n",
    "#print sentence\n",
    "\n",
    "def get_story(root_node):\n",
    "    act_sentence = root_node\n",
    "    story = []\n",
    "    while act_sentence:\n",
    "        story.append(nice_print_labSen(act_sentence.sentence))\n",
    "        if act_sentence.selected_child  >= 0:\n",
    "            act_sentence = act_sentence.children[act_sentence.selected_child]\n",
    "        else:\n",
    "            break\n",
    "    return story\n",
    "\n",
    "def log_json(root_node):\n",
    "    with open('log_json.txt','w') as output:\n",
    "        output.write(json.dumps(root_node.toJSON(),indent=2))\n",
    "    \n",
    "def log_story(root_node):\n",
    "    story = get_story(root_node)\n",
    "    with open('log_story.txt','w') as output:\n",
    "        for l in story:\n",
    "            output.write(l+'\\n')   \n",
    "    \n",
    "\n",
    "def print_story(root_node):\n",
    "    story = get_story(root_node)\n",
    "    for l in story:\n",
    "        print(l)   \n",
    "\n",
    "#print root_node.toJSON()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "//////\n",
      "The obstacles to an international agreement to reduce greenhouse gas emissions are many.\n",
      "//////\n",
      "0  The signs and symptoms of Lyme disease are numerous. 0.716039061546\n",
      "1  This contradiction manifests itself in many different forms. 0.697702407837\n",
      "2  Soil Degradation The causes of soil degradation are numerous. 0.691511511803\n",
      "3  The two most common are the SRF04 and SRF08. 0.678226590157\n",
      "4  Hydrocarbons are molecules of hydrogen and carbon atoms in many different combinations. 0.675856113434\n",
      "5  Many are of much greater complexity than the Atari VCS. 0.673483610153\n",
      "6  These organizational impediments are some of the chief barriers to implementation. 0.673454344273\n",
      "7  This contradiction manifests itself in many different forms. 0.67122989893\n",
      "8  He suggested that many of the world ’s oceans are underproducing. 0.670515060425\n",
      "9  The differences between Curry House CoCo Ichibanya and Yoshinoya ’s procedural rhetorics are numerous. 0.668774306774\n",
      "p This is the theory of autopoiesis, which we will discuss in chapter6.\n",
      ":::RRR:::\n",
      "r0 In addition to the ongoing flow of information, news agencies need sound bites, photos and video footage.\n",
      "r1 THE EXPRESSION OF THESE CONCEPTS CAN BE ACHIEVED ONLY THROUGH THE RHYTHMIC' HALLUCINATION OF THE WORD'.\n",
      "r2 Because of their oppression, blacks should be free to pursuea variety of political strategies, he said.\n",
      "r3 It is the very event of obscuring, a descent of the night, an invasion of shadow.\n",
      "r4 MM Mary Ann has been is familiar with the problem eccentricities of this machine.\n",
      "r5 This is because at the moment peer review is nota service that is provided by most open access self-archiving repositories.\n",
      "r6 It is in this sense less exclusive as compared to private ownership, although how to best use these shared computer resources remains an open question.\n",
      "r7 John Dewey and the Lessons of Art. New Haven: Yale University Press.\n",
      "r8 Mourning and funeral rites area necessary condition for an elaboration of the loss of the object.\n",
      "r9 Organisms all aim at ongoing stability and predictable response mechanisms; the body isa self-maintaining and bounded system that is not placed within matter or chaos, but gives itself its world.\n",
      "Next child: q\n"
     ]
    }
   ],
   "source": [
    "root_node = LabSentTreeNode(sentence)\n",
    "actual_node = root_node\n",
    "while actual_node:\n",
    "    clear_output()\n",
    "    log_json(root_node)\n",
    "    log_story(root_node)\n",
    "    print '//////'\n",
    "    print nice_print_labSen(actual_node.sentence)\n",
    "    print '//////'\n",
    "    actual_node.print_options()\n",
    "    actual_node = actual_node.select_child()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is due to the large reservoirs of carbon dioxide in the ocean, soil and biosphere, which are in equilibrium with the atmosphere ona time-scale of decades.\n",
      "This is due to the large reservoirs of carbon dioxide in the ocean, soil and biosphere, which are in equilibrium with the atmosphere ona time-scale of decades.\n",
      "This is the theory of autopoiesis, which we will discuss in chapter6.\n",
      "The obstacles to an international agreement to reduce greenhouse gas emissions are many.\n"
     ]
    }
   ],
   "source": [
    "print_story(root_node)\n",
    "\n",
    "#import json\n",
    "#print json.dumps(root_node.toJSON(),indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "root_node.toJSON()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
