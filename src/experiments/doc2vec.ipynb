{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "from IPython.display import clear_output\n",
    "import json\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "import pickle\n",
    "from IPython.core.display import display, HTML\n",
    "import locale\n",
    "locale.setlocale(locale.LC_ALL, 'de_DE.utf-8')\n",
    "\n",
    "# used for loading or saving\n",
    "model_file = '/home/ramin/projects/ECO/src/python/modelbuilder/parsed_v3_valid.doc2vec'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 2 Build sentence list (each sentence needs at least 1 tag)\n",
    "filename = '/home/marcel/drive/data/eco/NAIL_DATAFIELD_txt/parsed_v3/parsed_v3_valid.txt'\n",
    "\n",
    "sentences = []\n",
    "from random import shuffle\n",
    "\n",
    "for uid, line in enumerate(open(filename)):\n",
    "    ls = gensim.models.doc2vec.LabeledSentence(words=line.split(), tags=['SENT_%s' % uid])\n",
    "    sentences.append(ls)\n",
    "print(len(sentences),'sentences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 3 TRAINING OR LOADING the doc2vec model and save it\n",
    "# ALTERNATIVE: LOAD THE MODEL IN THE NEXT CELL\n",
    "\n",
    "# tutorial https://rare-technologies.com/doc2vec-tutorial/\n",
    "# proposes shuffling or learning reate adjustment. we gonna do both\n",
    "# in total 20 epochs\n",
    "# took ca. 6.30 hours\n",
    "\n",
    "# FOR SAFETY REASON, BUILD ONLY WHEN FLAG IS SET\n",
    "\n",
    "train_model = False\n",
    "do_tests = True\n",
    "\n",
    "if train_model:\n",
    "    model = gensim.models.Doc2Vec(alpha=0.025, min_alpha=0.025)  # use fixed learning rate\n",
    "    print('building vocab') \n",
    "    model.build_vocab(sentences)\n",
    "\n",
    "    base_alpha = model.alpha\n",
    "    base_min_alpha = model.min_alpha\n",
    "\n",
    "    for mepoch in range(2):\n",
    "        model.alpha = base_alpha \n",
    "        model.min_alpha = base_min_alpha\n",
    "        for epoch in range(10):\n",
    "            print('epoch',mepoch * 10 + epoch)\n",
    "            model.train(sentences)\n",
    "            model.alpha -= 0.002  # decrease the learning rate\n",
    "            model.min_alpha = model.alpha  # fix the learning rate, no decay\n",
    "        shuffle(sentences)\n",
    "\n",
    "    # saving the model    \n",
    "    model.save(model_file)\n",
    "    print 'model trained and saved'\n",
    "else:\n",
    "    model = gensim.models.Doc2Vec.load(model_file)\n",
    "    print 'model loaded'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 6 Tiny helper functions\n",
    "\n",
    "def print_word_list(wl):\n",
    "    str =  ' '.join(wl)\n",
    "    pattern = re.compile('\\s.\\s')\n",
    "    shift = 0\n",
    "    for ma in pattern.finditer(str):\n",
    "        str = str[:ma.start(0)-shift]+ma.group(0)[1:]+ str[ma.end(0)-shift:]\n",
    "        shift +=1\n",
    "    if str[-2] == ' ':\n",
    "        str = str[:-2] + str[-1:]\n",
    "    return str\n",
    "\n",
    "def get_print(sentence_or_similar):\n",
    "    if type(sentence_or_similar) is gensim.models.doc2vec.LabeledSentence:\n",
    "        word_list = sentence_or_similar[0]\n",
    "    elif type(sentence_or_similar) is int: # just an index\n",
    "        word_list = sentences[sentence_or_similar][0]\n",
    "    else: # TaggedDocument class\n",
    "        word_list = sentences[int(sentence_or_similar[0][5:])][0]\n",
    "    return print_word_list(word_list)\n",
    "\n",
    "    \n",
    "def get_index_tag(sentence):\n",
    "    return sentence[1][0]\n",
    "\n",
    "def get_index(sentence_or_similar):\n",
    "    if type(sentence_or_similar) is gensim.models.doc2vec.LabeledSentence:\n",
    "        return int(get_index_tag(sentence_or_similar)[5:])\n",
    "    else:\n",
    "        return int(sentence_or_similar[0][5:])\n",
    "    \n",
    "def equal_word_lists(index1, index2):\n",
    "    wl1 = sentences[index1][0]\n",
    "    wl2 = sentences[index2][0]\n",
    "    if len(wl1) != len(wl2):\n",
    "        return False\n",
    "    else:\n",
    "        for i in range(len(wl1)):\n",
    "            if wl1[i] != wl2[i]:\n",
    "                return False\n",
    "    return True\n",
    "\n",
    "def get_lab_sent_by_similar(similar):\n",
    "    print get_index(similar)\n",
    "    return sentences[get_index(similar)]\n",
    "\n",
    "def get_similarity_by_index(index1, index2):\n",
    "    return model_loaded.docvecs.similarity(index1,index2)\n",
    "\n",
    "# HTML Helper\n",
    "def pack_into_elem(tag, clazz, content):\n",
    "    return '<' + tag + ' class=\"' + clazz + '\"> ' + content+ ' </' + tag +'>'\n",
    "\n",
    "pre = '''<style>\n",
    "          .act {font-weight: bold}\n",
    "          .i {color: grey}\n",
    "          .sim {color: orange}\n",
    "          .n {color: blue}\n",
    "          .p {color: red}\n",
    "          .r {color: green}          \n",
    "     </style>'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 5 Test: printing sentence 9 and getting the most similar ones.\n",
    "if do_tests:\n",
    "    test_sentence_index = 2639533\n",
    "    print get_print(test_sentence_index)\n",
    "    sims = model.docvecs.most_similar('SENT_'+str(test_sentence_index),topn = 30)\n",
    "    print 'similar sentence',len(sims)\n",
    "    print '\\nSIMILAR SENTENCES\\n'\n",
    "    for sim in sims:\n",
    "        print get_print(sim),sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 7 Test: iterate over similar sentences\n",
    "# needs the sentences loaded (cell 2)\n",
    "if do_tests:\n",
    "    index = 1983\n",
    "    # len(sentences)\n",
    "    # print sentences[index]\n",
    "    sentence = get_print(index)\n",
    "    print sentence\n",
    "    selected_indices = [index]\n",
    "\n",
    "    for sentence in range(10):\n",
    "        sims = model_loaded.docvecs.most_similar('SENT_'+str(index))\n",
    "        while True:\n",
    "            selected = random.choice(sims)\n",
    "            check_index = int(selected[0][5:])\n",
    "            if check_index not in selected_indices:\n",
    "                break\n",
    "        index = check_index\n",
    "        selected_indices.append(index)\n",
    "        print nice_print(selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 8 Story Treenode class\n",
    "\n",
    "PARENT = -1\n",
    "QUIT = -2\n",
    "NEXT = -3\n",
    "\n",
    "num_similars = 10\n",
    "num_random = 10\n",
    "\n",
    "class LabSentTreeNode:\n",
    "    \n",
    "    def __init__(self, labeledSentence, parent = None):\n",
    "        self.sentence = labeledSentence\n",
    "        self.sentence_index = get_index(self.sentence)\n",
    "        self.similars = self.get_similars()  \n",
    "        self.randoms = self.get_randoms()\n",
    "        self.children = {} # index: SentenceTreeNode\n",
    "        self.selected_child = '' # None\n",
    "        self.parent = parent\n",
    "             \n",
    "    def get_similars(self):\n",
    "        return model_loaded.docvecs.most_similar(get_index_tag(self.sentence),topn = num_similars)\n",
    "    \n",
    "    def get_randoms(self):\n",
    "        randoms = []\n",
    "        for index in range(num_random):\n",
    "            rnd_sen = sentences[random.randint(0,len(sentences))]\n",
    "            randoms.append(rnd_sen)     \n",
    "        return randoms\n",
    "                \n",
    "    def print_options(self):\n",
    "        for index, sentence in enumerate(self.similars):\n",
    "            add = '(*)' if get_similar_index(sentence) in self.children else ''\n",
    "            print index, add, get_print(sentence), \"%.3f\" % sentence[1]\n",
    "        if self.parent:\n",
    "            print 'p: ', get_print(self.parent.sentence)\n",
    "        if self.sentence_index < len(sentences) - 2:\n",
    "            print 'n: ', get_print(sentences[self.sentence_index + 1])           \n",
    "        for index,sentence in enumerate(self.randoms):\n",
    "            print 'r'+str(index) +\": \",  get_print(sentence)\n",
    "            \n",
    "    def get_options_html(self):\n",
    "        html = ''\n",
    "        for index, sentence in enumerate(self.similars):\n",
    "            content = pack_into_elem('span','',nice_print(sentence))\n",
    "            index = pack_into_elem('span','',str(index)+': ')\n",
    "            sentence_index = get_index(sentence)\n",
    "            index += '❗️' if sentence_index in added_sentences else ''\n",
    "            index_distance =  locale.format('%d', abs(self.sentence_index - sentence_index), 1)\n",
    "            similar = pack_into_elem('span','sim',(\"%.3f\" % sentence[1]) + ' / ' + str(index_distance))\n",
    "            html += pack_into_elem('div', '', index + content + similar)\n",
    "        if self.parent:\n",
    "            content = pack_into_elem('span','',nice_print_labSen(self.parent.sentence))\n",
    "            index = pack_into_elem('span','','P: ')\n",
    "            sentence_index = self.parent.sentence_index\n",
    "            index_distance =  locale.format('%d', abs(self.sentence_index - sentence_index), 1)\n",
    "            similarity = get_similarity_by_index(self.sentence_index, self.parent.sentence_index)\n",
    "            similar = pack_into_elem('span','sim',(\"%.3f\" % similarity) + ' / ' + str(index_distance))\n",
    "            html += pack_into_elem('div', 'p', index + content + similar)\n",
    "        if self.sentence_index < len(sentences) - 2:\n",
    "            content = pack_into_elem('span','n',nice_print_labSen(sentences[self.sentence_index + 1]))\n",
    "            index = pack_into_elem('span','','N: ')\n",
    "            sentence_index = self.sentence_index + 1\n",
    "            index += '❗️' if sentence_index in added_sentences else ''\n",
    "            index_distance =  locale.format('%d', abs(self.sentence_index - sentence_index), 1)\n",
    "            similarity = get_similarity_by_index(self.sentence_index, self.sentence_index + 1)\n",
    "            similar = pack_into_elem('span','sim',(\"%.3f\" % similarity) + ' / ' + str(index_distance))\n",
    "            html += pack_into_elem('div', 'n', index + content + similar)\n",
    "        for index,sentence in enumerate(self.randoms):\n",
    "            content = pack_into_elem('span','',nice_print_labSen(sentence))\n",
    "            index = pack_into_elem('span','','R'+str(index)+': ')\n",
    "            sentence_index = get_index(sentence)\n",
    "            index += '❗️' if sentence_index in added_sentences else ''\n",
    "            index_distance =  locale.format('%d', abs(self.sentence_index - sentence_index), 1)\n",
    "            index_distance =  locale.format('%d', abs(self.sentence_index - sentence_index), 1)\n",
    "            similarity = get_similarity_by_index(self.sentence_index, get_index(sentence))\n",
    "            similar = pack_into_elem('span','sim',(\"%.3f\" % similarity) + ' / ' + str(index_distance))\n",
    "            html += pack_into_elem('div', 'r', index + content + similar)\n",
    "        html += pack_into_elem('div', '', 'Q: Quit 💣')\n",
    "        return html\n",
    "    \n",
    "    def get_sentence_html(self):\n",
    "        return pack_into_elem('p', 'act', nice_print_labSen(self.sentence))\n",
    "    \n",
    "    def select_child(self):\n",
    "        u_input = raw_input('Next child: ')\n",
    "        if u_input == 'p':\n",
    "            selected_index = PARENT\n",
    "        elif u_input == 'q':\n",
    "            return None\n",
    "        elif u_input == 'n':\n",
    "            selected_index = NEXT\n",
    "        elif u_input.startswith('r'):\n",
    "            selected_index = 100 + int(u_input[1:])\n",
    "        else:\n",
    "            try:\n",
    "                selected_index = int(u_input)\n",
    "            except ValueError:\n",
    "                return self\n",
    "        if selected_index >= 0 and selected_index < len(self.similars):\n",
    "            lab_sent = get_lab_sent_by_similar(self.similars[selected_index])\n",
    "            child =  LabSentTreeNode(lab_sent, self)\n",
    "            self.children[u_input] = child\n",
    "            self.selected_child = u_input\n",
    "            return child\n",
    "        elif selected_index >= 100 and selected_index < len(self.randoms) + 100:\n",
    "            #print 'random sen'\n",
    "            child =  LabSentTreeNode(self.randoms[selected_index - 100], self)\n",
    "            self.children[u_input] = child\n",
    "            self.selected_child = u_input   \n",
    "            return child\n",
    "        elif selected_index == PARENT and self.parent:\n",
    "            return self.parent\n",
    "        elif selected_index == NEXT:\n",
    "            child =  LabSentTreeNode(sentences[self.sentence_index + 1], self)\n",
    "            self.children[u_input] = child\n",
    "            self.selected_child = u_input   \n",
    "            return child\n",
    "        # a weird number\n",
    "        return self\n",
    "        \n",
    "    def toJSON(self):\n",
    "        children_toJSON = {}\n",
    "        for child_index in self.children:\n",
    "            children_toJSON[child_index] = self.children[child_index].toJSON()\n",
    "            \n",
    "        return {'sentence':nice_print_labSen(self.sentence),\n",
    "                'index':get_index(self.sentence),\n",
    "               'children':children_toJSON,\n",
    "                'selected_child':self.selected_child\n",
    "               }  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 8 Story creator/log helper functions\n",
    "\n",
    "def get_story(root_node):\n",
    "    act_sentence = root_node\n",
    "    story = []\n",
    "    while act_sentence:\n",
    "        story.append(nice_print_labSen(act_sentence.sentence))\n",
    "        if act_sentence.selected_child  != '':\n",
    "            act_sentence = act_sentence.children[act_sentence.selected_child]\n",
    "        else:\n",
    "            break\n",
    "    return story\n",
    "\n",
    "def log_json(root_node):\n",
    "    with open('log.json','w') as output:\n",
    "        output.write(json.dumps(root_node.toJSON(),indent=2))\n",
    "    \n",
    "def log_story(root_node):\n",
    "    story = get_story(root_node)\n",
    "    with open('story.txt','w') as output:\n",
    "        for l in story:\n",
    "            output.write(l+'\\n')   \n",
    "    \n",
    "def print_story(root_node):\n",
    "    story = get_story(root_node)\n",
    "    for l in story:\n",
    "        print(l)   \n",
    "\n",
    "def dump_story(root_node):\n",
    "    with open('story.dump','w') as dump_file:\n",
    "        pickle.dump(root_node,dump_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 9 Story creator\n",
    "\n",
    "load_from_log = True\n",
    "\n",
    "added_sentences = set()  \n",
    "\n",
    "if load_from_log:\n",
    "    with open('story.dump','r') as in_file:    \n",
    "        root_node = pickle.load(in_file)\n",
    "        actual_node = root_node\n",
    "        while actual_node.selected_child != '':\n",
    "            added_sentences.add(actual_node.sentence_index)\n",
    "            actual_node = actual_node.children[actual_node.selected_child]\n",
    "            \n",
    "else:  \n",
    "    sentence = sentences[random.randint(0,len(sentences))]\n",
    "    root_node = LabSentTreeNode(sentence)\n",
    "    actual_node = root_node\n",
    "\n",
    "while actual_node:\n",
    "    clear_output()\n",
    "    log_json(root_node)\n",
    "    log_story(root_node)\n",
    "    dump_story(root_node)\n",
    "    added_sentences.add(actual_node.sentence_index)\n",
    "    display(HTML(pre + actual_node.get_sentence_html() + actual_node.get_options_html()))\n",
    "    time.sleep(0.4)\n",
    "    actual_node = actual_node.select_child()\n",
    "clear_output()\n",
    "print '📖 ⭐ 📖'\n",
    "print_story(root_node)\n",
    "print '👋🏽'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TRYING TO TRAIN MORE\n",
    "# RUNS BUT DOESNT EXTEND THE MODEL FILE\n",
    "print len(model_loaded.docvecs)\n",
    "line = 'Therefore, if you tell me the truth, they are not going to reject what you say.'\n",
    "ls = gensim.models.doc2vec.LabeledSentence(words=line.split(), tags=['SENT_%s' % len(sentences)])\n",
    "sentences.append(ls)\n",
    "model.train([ls])\n",
    "print len(model_loaded.docvecs)\n",
    "print sentences[len(sentences)-1]\n",
    "get_similarity_by_index(len(sentences)-1,400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Findings\n",
    "next to similarity(d1,d2) there is also n_similarity(ds1, ds2), which takes lists.\n",
    "```\n",
    "s_index = 400\n",
    "s = sentences[s_index]\n",
    "res = model_loaded.docvecs.most_similar(get_index(s))\n",
    "# print res\n",
    "for s in res:\n",
    "    print nice_print(s)\n",
    "    print s[1]\n",
    "    index = get_index(s)\n",
    "    print get_similarity_by_index(s_index,index)\n",
    "    print model_loaded.docvecs.n_similarity([s_index],[index])\n",
    "    print '######'\n",
    "    \n",
    "```\n",
    "resulting in:\n",
    "```\n",
    "0.570710778236\n",
    "0.570710771218\n",
    "0.570710771218\n",
    "######\n",
    "I have only been twice; so many things bewildered me.\n",
    "0.563167154789\n",
    "0.563167148085\n",
    "0.563167148085\n",
    "######\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
