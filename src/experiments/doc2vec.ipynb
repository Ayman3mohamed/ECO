{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "# used for loading or saving\n",
    "model_file = '/home/ramin/projects/ECO/src/python/modelbuilder/parsed_v3_valid.doc2vec'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4266193, 'sentences')\n"
     ]
    }
   ],
   "source": [
    "# 2 Build sentence list (each sentence needs at least 1 tag)\n",
    "filename = '/home/marcel/drive/data/eco/NAIL_DATAFIELD_txt/parsed_v3/parsed_v3_valid.txt'\n",
    "\n",
    "sentences = []\n",
    "from random import shuffle\n",
    "\n",
    "for uid, line in enumerate(open(filename)):\n",
    "    ls = gensim.models.doc2vec.LabeledSentence(words=line.split(), tags=['SENT_%s' % uid])\n",
    "    sentences.append(ls)\n",
    "print(len(sentences),'sentences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building vocab\n",
      "('epoch', 0)\n",
      "('epoch', 1)\n",
      "('epoch', 2)\n",
      "('epoch', 3)\n",
      "('epoch', 4)\n",
      "('epoch', 5)\n",
      "('epoch', 6)\n",
      "('epoch', 7)\n",
      "('epoch', 8)\n",
      "('epoch', 9)\n",
      "('epoch', 10)\n",
      "('epoch', 11)\n",
      "('epoch', 12)\n",
      "('epoch', 13)\n",
      "('epoch', 14)\n",
      "('epoch', 15)\n",
      "('epoch', 16)\n",
      "('epoch', 17)\n",
      "('epoch', 18)\n",
      "('epoch', 19)\n"
     ]
    }
   ],
   "source": [
    "# 3 Training the doc2vec model\n",
    "\n",
    "# tutorial https://rare-technologies.com/doc2vec-tutorial/\n",
    "# proposes shuffling or learning reate adjustment. we gonna do both\n",
    "# in total 20 epochs\n",
    "# took ca. 6.30 hours\n",
    "model = gensim.models.Doc2Vec(alpha=0.025, min_alpha=0.025)  # use fixed learning rate\n",
    "print('building vocab') \n",
    "model.build_vocab(sentences)\n",
    "\n",
    "base_alpha = model.alpha\n",
    "base_min_alpha = model.min_alpha\n",
    "\n",
    "for mepoch in range(2):\n",
    "    model.alpha = base_alpha \n",
    "    model.min_alpha = base_min_alpha\n",
    "    for epoch in range(10):\n",
    "        print('epoch',mepoch * 10 + epoch)\n",
    "        model.train(sentences)\n",
    "        model.alpha -= 0.002  # decrease the learning rate\n",
    "        model.min_alpha = model.alpha  # fix the learning rate, no decay\n",
    "    shuffle(sentences)\n",
    "\n",
    "# saving the model    \n",
    "model.save(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 4 Loading the model\n",
    "\n",
    "model_loaded = gensim.models.Doc2Vec.load(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Haven , CT : Yale University Press .\n",
      "similar sentence 10\n",
      "\n",
      "SIMILAR SENTENCES\n",
      "\n",
      "New Haven, CT: Yale University Press. ('SENT_2310654', 0.9655746221542358)\n",
      "New Haven, CT: Yale University Press. ('SENT_2310654', 0.9655746221542358)\n",
      "New Haven, CT: Yale University Press. ('SENT_2310654', 0.9655746221542358)\n",
      "New Haven, CT: Yale University Press. ('SENT_2310654', 0.9655746221542358)\n",
      "New Haven, CT: Yale University Press. ('SENT_2310654', 0.9655746221542358)\n",
      "New Haven, CT: Yale University Press. ('SENT_2310654', 0.9655746221542358)\n",
      "New Haven, CT: Yale University Press. ('SENT_2310654', 0.9655746221542358)\n",
      "New Haven, CT: Yale University Press. ('SENT_2310654', 0.9655746221542358)\n",
      "New Brunswick, NJ: Rutgers University Press. ('SENT_2310654', 0.9655746221542358)\n",
      "New Haven, CT: Yale University Press. ('SENT_2310654', 0.9655746221542358)\n"
     ]
    }
   ],
   "source": [
    "# 5 Test: printing sentence 9 and getting the most similar ones.\n",
    "test_sentence_index = 2639533\n",
    "\n",
    "print ' '.join(sentences[test_sentence_index][0])\n",
    "sims = model_loaded.docvecs.most_similar('SENT_'+str(test_sentence_index))\n",
    "print 'similar sentence',len(sims)\n",
    "print '\\nSIMILAR SENTENCES\\n'\n",
    "for sim in sims:\n",
    "    print nice_print(sim),sims[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 6 Tiny helper\n",
    "import re\n",
    "\n",
    "def nice_print(tagged_doc):\n",
    "    sentence = sentences[int(tagged_doc[0][5:])][0]\n",
    "    str =  ' '.join(sentence)\n",
    "    pattern = re.compile('\\s.\\s')\n",
    "    shift = 0\n",
    "    for ma in pattern.finditer(str):\n",
    "        str = str[:ma.start(0)-shift]+ma.group(0)[1:]+ str[ma.end(0)-shift:]\n",
    "        shift +=1\n",
    "    if str[-2] == ' ':\n",
    "        str = str[:-2] + str[-1:]\n",
    "    return str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a classic example of scientific discovery being concerned with the union of opposites : Kepler ’ s laws and Galileo ’ s laws being both reconciled and superseded by a principle which was both superior to both and yet comprehended both .\n",
      "Where they are effective, both mechanisms establish cooperation in the same way.\n",
      "Where the mechanisms fail, both do so for the same reason.\n",
      "All closures are thus both existentially true and ideally false.\n",
      "Ideally, you should read both at the same time.\n",
      "In the next section we shall consider both these topics.\n",
      "Data were collected during both the rainy and dry seasons.\n",
      "The data from both the Svinøy section and Barents Sea Opening are de-seasoned.\n",
      "Mr. Johnson sued both Mr. Womack and Hooters.\n",
      "Burkina Faso, allied with both COtc d'Ivoire and Libya.\n",
      "It was both bathetically funny and extremely poignant.\n",
      "He sums up muchof whatis containedin both of the scatologicalimages thathavebeen examinedhere.\n",
      "I ’ ve been both for ﬁve years.\n",
      "He was an adjunct professor at both New York Institute of Technology and Georgetown University.\n",
      "He teaches at the Gerrit Rietveld Academie and at the Academy of Architecture, both in Amsterdam.\n",
      "We were both very mu aﬀected at this interview.\n",
      "The Rasabox exercise was developed both during ECA rehearsal workshops and at workshopsI ran at NYU in the 1990s.\n",
      "The GENESIS climate model was developed at the National Center for Atmospheric Research by Starley Thompson and Dave Pollard.\n",
      "There is no reason why LDCs could not be developed differentially.\n",
      "The Annex to the Agreement addressesa number of issues raised by developed states.\n",
      "Based on this idea, the researchers developeda set of graphical representations of abstract concepts.\n",
      "Since that time, our ideas have grown and developed.\n",
      "This led to tensions between developed and developing countries.\n",
      "JOHN KELSEY ISA CONTRIBUTING EDITOR OF ARTFORUM.\n",
      "JOHN KELSEY ISA CONTRIBUTING EDITOR OF ARTFORUM.\n",
      "HE IS ALSOA MEMBER OF THE COLLECTIVE BERNADETTE CORPORATION AND COFOUNDER OF REENA SPAUUNGS FINE ART IN NEW YORK.\n",
      "EMPLOYING MIXED CASE FOR THE BULK OF THE TEXT CREATESA GENTLER, MORE MODERATE TONE AND HELPS GIVE THE OCCASIONAL USE OF CAPITALS GREATER IMPACT.\n",
      "NIGEL THRIFT IS HEAD OF THE DIVISION OF LIFE AND ENVIRONMENTAL SCIENCES ANDA PROFESSOR OF GEOGRAPHY AT THE UNIVERSITY OF OXFORD.\n",
      "THERE WAS ONCEA TOWN IN THE HEART OF AMERICA WHERE ALL LIFE SEEMED TO LIVE IN HARMONY WITH ITS SURROUNDINGS.\n",
      "Baltimore, MD: Johns Hopkins University Press.\n",
      "Baltimore, MD: Johns Hopkins University Press.\n",
      "Baltimore, MD: Johns Hopkins University Press.\n",
      "Baltimore, MD: Johns Hopkins University Press.\n",
      "Baltimore, MD: Johns Hopkins University Press.\n",
      "New Haven, CT: Yale University Press.\n",
      "New Haven, CT: Yale University Press.\n",
      "New Haven, CT: Yale University Press.\n",
      "New Haven, CT: Yale University Press.\n",
      "New Brunswick, NJ: Rutgers University Press.\n",
      "New York: Oxford University Press, 1990.\n",
      "New Haven, CT: Yale University Press.\n",
      "New Haven, CT: Yale University Press.\n",
      "New Haven, CT: Yale University Press.\n",
      "New Haven, CT: Yale University Press.\n",
      "New Brunswick, NJ: Rutgers University Press.\n",
      "New Haven, CT: Yale University Press.\n",
      "New Haven, CT: Yale University Press.\n",
      "New Haven, CT: Yale University Press.\n",
      "New Haven, CT: Yale University Press.\n",
      "New Haven, CT: Yale University Press.\n",
      "New Haven, CT: Yale University Press.\n",
      "New Haven, CT: Yale University Press.\n",
      "New Haven, CT: Yale University Press.\n",
      "New Haven, CT: Yale University Press.\n",
      "New Haven, CT: Yale University Press.\n",
      "New Haven, CT: Yale University Press.\n",
      "New Haven, CT: Yale University Press.\n",
      "New Haven, CT: Yale University Press.\n",
      "New Haven, CT: Yale University Press.\n",
      "New Haven, CT: Yale University Press.\n",
      "New Haven, CT: Yale University Press.\n",
      "New Haven, CT: Yale University Press.\n",
      "New Haven, CT: Yale University Press.\n",
      "New Haven, CT: Yale University Press.\n",
      "New Haven, CT: Yale University Press.\n",
      "New Haven, CT: Yale University Press.\n",
      "New Haven, CT: Yale University Press.\n",
      "New Haven, CT: Yale University Press.\n",
      "New Haven, CT: Yale University Press.\n",
      "New York: Columbia University Press, 1991.\n",
      "New York: Columbia University Press, 1986.\n",
      "New York: Columbia University Press, 1986.\n",
      "New York: Oxford University Press, 1988.\n",
      "New York: Oxford University Press, 1996.\n",
      "New Haven, CT: Yale University Press.\n",
      "New Haven, CT: Yale University Press.\n",
      "New Haven, CT: Yale University Press.\n",
      "New Haven, CT: Yale University Press.\n",
      "New Haven, CT: Yale University Press.\n",
      "New Haven, CT: Yale University Press.\n",
      "New Haven, CT: Yale University Press.\n",
      "New Haven, CT: Yale University Press.\n",
      "New Haven, CT: Yale University Press.\n",
      "New Haven, CT: Yale University Press.\n",
      "New Haven, CT: Yale University Press.\n",
      "New Haven, CT: Yale University Press.\n",
      "New Brunswick, NJ: Rutgers University Press.\n",
      "New Brunswick, N.J.: Rutgers University Press.\n",
      "New Brunswick, NJ: Rutgers University Press.\n",
      "New Brunswick, N.J.: Rutgers University Press.\n",
      "New Brunswick, NJ: Rutgers University Press.\n",
      "New York, NY: Oxford University Press.\n",
      "New Haven, CT: Yale University Press.\n",
      "New Haven, CT: Yale University Press.\n",
      "New Haven, CT: Yale University Press.\n",
      "New Haven, CT: Yale University Press.\n",
      "New Haven, CT: Yale University Press.\n",
      "New Haven, CT: Yale University Press.\n",
      "New Haven, CT: Yale University Press.\n",
      "New Haven, CT: Yale University Press.\n",
      "New Haven, CT: Yale University Press.\n"
     ]
    }
   ],
   "source": [
    "# 7 \n",
    "# iterate over similar sentences\n",
    "# needs the sentences loaded (cell 2)\n",
    "import random\n",
    "\n",
    "index = 1983\n",
    "# len(sentences)\n",
    "# print sentences[index]\n",
    "sentence = ' '.join(sentences[index][0])\n",
    "print sentence\n",
    "selected_indices = [index]\n",
    "\n",
    "for sentence in range(100):\n",
    "    sims = model_loaded.docvecs.most_similar('SENT_'+str(index))\n",
    "    while True:\n",
    "        selected = random.choice(sims)\n",
    "        check_index = int(selected[0][5:])\n",
    "        if check_index not in selected_indices:\n",
    "            break\n",
    "    index = check_index\n",
    "    selected_indices.append(index)\n",
    "    print nice_print(selected)\n",
    "#     print selected_indices\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1983, 2814331, 2814342, 495138, 676738, 371789, 2920081, 2061257, 3249416, 4012678, 102480, 964039, 4069641, 1277748, 260020, 4123171, 822746, 2256952, 2097819, 3519909, 624089, 3412895, 3358142, 446522, 446585, 446523, 834376, 2836531, 2491127, 3747155, 1193547, 753166, 761321, 1955724, 1039614, 2034311, 2148966, 1955728, 3181740, 2216191, 2871939, 2366354, 454937, 2476339, 2372262, 1636212, 2370045, 305257, 2179857, 2690562, 1941260, 2690436, 1940521, 2871678, 2373089, 3275265, 313266, 2374079, 1572408, 3293155, 2746599, 1110669, 1922210, 2036288, 2031490, 2370074, 2336955, 2308796, 3416431, 71570, 371050, 355919, 371080, 1416359, 3287806, 2238712, 2034483, 2372169, 2130563, 2690977, 2364576, 2036451, 2372898, 1636080, 2567033, 2859977, 3588027, 4081204, 1157194, 2257439, 2367598, 2767805, 3287742, 2373551, 2366485, 1972444, 2032001, 2131374, 1940547, 2560974, 2639533]\n"
     ]
    }
   ],
   "source": [
    "print selected_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/marcel/projects/eco/src/experiments\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "cwd = os.getcwd()\n",
    "print cwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
