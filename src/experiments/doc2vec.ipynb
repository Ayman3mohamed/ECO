{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "# used for loading or saving\n",
    "model_file = '/home/ramin/projects/ECO/src/python/modelbuilder/parsed_v3_valid.doc2vec'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4266193, 'sentences')\n"
     ]
    }
   ],
   "source": [
    "# 2 Build sentence list (each sentence needs at least 1 tag)\n",
    "filename = '/home/marcel/drive/data/eco/NAIL_DATAFIELD_txt/parsed_v3/parsed_v3_valid.txt'\n",
    "\n",
    "sentences = []\n",
    "from random import shuffle\n",
    "\n",
    "for uid, line in enumerate(open(filename)):\n",
    "    ls = gensim.models.doc2vec.LabeledSentence(words=line.split(), tags=['SENT_%s' % uid])\n",
    "    sentences.append(ls)\n",
    "print(len(sentences),'sentences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 3 Training the doc2vec model\n",
    "### ALTERNATIVE\n",
    "### JUST LOAD IT WITH THE NEXT CELL\n",
    "### FOR SECURITY REASONS, LETS HAVE A FLAG\n",
    "\n",
    "# tutorial https://rare-technologies.com/doc2vec-tutorial/\n",
    "# proposes shuffling or learning reate adjustment. we gonna do both\n",
    "# in total 20 epochs\n",
    "# took ca. 6.30 hours\n",
    "\n",
    "build_model = False\n",
    "\n",
    "if build_model:\n",
    "    model = gensim.models.Doc2Vec(alpha=0.025, min_alpha=0.025)  # use fixed learning rate\n",
    "    print('building vocab') \n",
    "    model.build_vocab(sentences)\n",
    "\n",
    "    base_alpha = model.alpha\n",
    "    base_min_alpha = model.min_alpha\n",
    "\n",
    "    for mepoch in range(2):\n",
    "        model.alpha = base_alpha \n",
    "        model.min_alpha = base_min_alpha\n",
    "        for epoch in range(10):\n",
    "            print('epoch',mepoch * 10 + epoch)\n",
    "            model.train(sentences)\n",
    "            model.alpha -= 0.002  # decrease the learning rate\n",
    "            model.min_alpha = model.alpha  # fix the learning rate, no decay\n",
    "        shuffle(sentences)\n",
    "\n",
    "    # saving the model    \n",
    "    model.save(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 4 Loading the model\n",
    "\n",
    "model_loaded = gensim.models.Doc2Vec.load(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 5 TEST: printing sentence 9 and getting the most similar ones.\n",
    "test_sentence_index = 2639533\n",
    "\n",
    "print ' '.join(sentences[test_sentence_index][0])\n",
    "sims = model_loaded.docvecs.most_similar('SENT_'+str(test_sentence_index),topn = 30)\n",
    "print 'similar sentence',len(sims)\n",
    "print '\\nSIMILAR SENTENCES\\n'\n",
    "for sim in sims:\n",
    "    print nice_print(sim),sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 6 Tiny helper\n",
    "import re\n",
    "\n",
    "def print_word_list(wl):\n",
    "    str =  ' '.join(wl)\n",
    "    pattern = re.compile('\\s.\\s')\n",
    "    shift = 0\n",
    "    for ma in pattern.finditer(str):\n",
    "        str = str[:ma.start(0)-shift]+ma.group(0)[1:]+ str[ma.end(0)-shift:]\n",
    "        shift +=1\n",
    "    if str[-2] == ' ':\n",
    "        str = str[:-2] + str[-1:]\n",
    "    return str\n",
    "\n",
    "def nice_print(tagged_doc):\n",
    "    word_list = sentences[int(tagged_doc[0][5:])][0]\n",
    "    return print_word_list(word_list)\n",
    "\n",
    "def print_similar(similar):\n",
    "    return nice_print(similar)\n",
    "\n",
    "def nice_print_labSen(labeledSentence):\n",
    "    return print_word_list(labeledSentence[0])\n",
    "\n",
    "def print_index(index):\n",
    "    sentence = ' '.join(sentences[index][0])\n",
    "    return sentence\n",
    "    \n",
    "def get_similar_index(similar):\n",
    "    return int(similar[0][5:])\n",
    "       \n",
    "def get_index_tag(labeledSentence):\n",
    "    return labeledSentence[1][0]\n",
    "\n",
    "def get_index(labeledSentence):\n",
    "    return int(get_index_tag(labeledSentence)[5:])\n",
    "    \n",
    "def equal_word_lists(index1, index2):\n",
    "    wl1 = sentences[index1][0]\n",
    "    wl2 = sentences[index2][0]\n",
    "    if len(wl1) != len(wl2):\n",
    "        return False\n",
    "    else:\n",
    "        for i in range(len(wl1)):\n",
    "            if wl1[i] != wl2[i]:\n",
    "                return False\n",
    "    return True\n",
    "\n",
    "def get_lab_sent_by_similar(similar):\n",
    "    print get_similar_index(similar)\n",
    "    return sentences[get_similar_index(similar)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 7 TEST\n",
    "# iterate over similar sentences\n",
    "# needs the sentences loaded (cell 2)\n",
    "import random\n",
    "\n",
    "index = 1983\n",
    "# len(sentences)\n",
    "# print sentences[index]\n",
    "sentence = ' '.join(sentences[index][0])\n",
    "print sentence\n",
    "selected_indices = [index]\n",
    "\n",
    "for sentence in range(100):\n",
    "    sims = model_loaded.docvecs.most_similar('SENT_'+str(index))\n",
    "    while True:\n",
    "        selected = random.choice(sims)\n",
    "        check_index = int(selected[0][5:])\n",
    "        if check_index not in selected_indices:\n",
    "            break\n",
    "    index = check_index\n",
    "    selected_indices.append(index)\n",
    "    print nice_print(selected)\n",
    "#     print selected_indices\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 8 Story TreeNode class\n",
    "\n",
    "import random\n",
    "\n",
    "class LabSentTreeNode:\n",
    "    \n",
    "    def __init__(self, labeledSentence, parent = None):\n",
    "        self.sentence = labeledSentence\n",
    "#       self.sentence_index = sentence_index\n",
    "        self.similars = self.get_similars()  \n",
    "        self.randoms = []\n",
    "        self.children = {} # index: SentenceTreeNode\n",
    "        self.selected_child = -1 # None\n",
    "        self.parent = parent\n",
    "             \n",
    "    def get_similars(self):\n",
    "        return model_loaded.docvecs.most_similar(get_index_tag(self.sentence),topn = 10)\n",
    "    \n",
    "    def print_options(self):\n",
    "        for index, sentence in enumerate(self.similars):\n",
    "            print index, '(*)' if get_similar_index(sentence) in self.children else '', nice_print(sentence), sentence[1]\n",
    "        if self.parent:\n",
    "            print 'p', nice_print_labSen(self.parent.sentence)\n",
    "        print ':::Randoms:::'\n",
    "        for index in range(10):\n",
    "            rnd_sen = sentences[random.randint(0,len(sentences))]\n",
    "            self.randoms.append(rnd_sen)\n",
    "            print 'r'+str(index),  nice_print_labSen(rnd_sen)\n",
    "            \n",
    "    def select_child(self):\n",
    "        u_input = raw_input('Next child: ')\n",
    "        if u_input == 'p':\n",
    "            u_input = -1\n",
    "        elif u_input == 'q':\n",
    "            u_input = -2\n",
    "        elif u_input.startswith('r'):\n",
    "            u_input = 100 + int(u_input[1:])\n",
    "        try:\n",
    "            selected_index = int(u_input)\n",
    "        except ValueError:\n",
    "            return self\n",
    "        if selected_index >= 0 and selected_index < len(self.similars):\n",
    "            lab_sent = get_lab_sent_by_similar(self.similars[selected_index])\n",
    "            child =  LabSentTreeNode(lab_sent, self)\n",
    "            self.children[selected_index] = child\n",
    "            self.selected_child = selected_index\n",
    "            return child\n",
    "        elif selected_index >= 100 and selected_index < len(self.randoms) + 100:\n",
    "            print 'random sen'\n",
    "            child =  LabSentTreeNode(self.randoms[selected_index - 100], self)\n",
    "            self.children[selected_index] = child\n",
    "            self.selected_child = selected_index    \n",
    "            return child\n",
    "        elif u_input == -1 and self.parent:\n",
    "            return self.parent\n",
    "        elif u_input == -2:\n",
    "            return None\n",
    "        \n",
    "    def toJSON(self):\n",
    "        return {'sentence':nice_print_labSen(self.sentence),\n",
    "                'index':get_index(self.sentence),\n",
    "               'children':[self.children[child_index].toJSON() for child_index in self.children]\n",
    "               }\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 9 Story creator log/helper functions\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import json\n",
    "\n",
    "def get_story(root_node):\n",
    "    act_sentence = root_node\n",
    "    story = []\n",
    "    while act_sentence:\n",
    "        story.append(nice_print_labSen(act_sentence.sentence))\n",
    "        if act_sentence.selected_child  >= 0:\n",
    "            act_sentence = act_sentence.children[act_sentence.selected_child]\n",
    "        else:\n",
    "            break\n",
    "    return story\n",
    "\n",
    "def log_json(root_node):\n",
    "    with open('log_json.txt','w') as output:\n",
    "        output.write(json.dumps(root_node.toJSON(),indent=2))\n",
    "    \n",
    "def log_story(root_node):\n",
    "    story = get_story(root_node)\n",
    "    with open('log_story.txt','w') as output:\n",
    "        for l in story:\n",
    "            output.write(l+'\\n')   \n",
    "    \n",
    "def print_story(root_node):\n",
    "    story = get_story(root_node)\n",
    "    for l in story:\n",
    "        print(l)   \n",
    "\n",
    "#print root_node.toJSON()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "//////\n",
      "Because the GNU GPL won ’t let them do that.\n",
      "//////\n",
      "0  We don ’t want to let them do that. 0.887139320374\n",
      "1  And let them do what they wanted to do. 0.861190795898\n",
      "2  Well, I don ’t really do that anymore. 0.846694588661\n",
      "3  I don ’t want to do that. 0.844094991684\n",
      "4  We ’ ll explain how to do that in Chapter2. 0.833934009075\n",
      "5  He didn ’t want to do that. 0.823796033859\n",
      "6  You ’ re not going to do that. 0.812620222569\n",
      "7  And to do that, you ’ ll need to learn the basics. 0.806607484818\n",
      "8  Do you think that breaksfrom that. .. 0.801155567169\n",
      "9  I do n't know whatI 'm going to do. 0.797776579857\n",
      "p The design was based on the metastable aggregation of architecture and information.\n",
      ":::RRR:::\n",
      "r0 Among the lettersI have received, about 10 percent are stories of attacks people suffered during their European vacations.\n",
      "r1 Equally inspiring was the attitude of many poor working-men.\n",
      "r2 There area few additional caveats to consider in this analysis.\n",
      "r3 In Proceedings of the IEEE International Conference on Robotics and Automation.\n",
      "r4 Standardization in action: Achieving local universality through medical protocols.\n",
      "r5 The thick theory claims consent; the thin theory settles for resignation.\n",
      "r6 But then he always came back laden with booty and all was forgiven.\n",
      "r7 Even if you havea great team, its collective ability isn ’t simply the sum of the team members ’ individual abilities.\n",
      "r8 Consider the ancestor of the Menger sponge, the Cantor set.\n",
      "r9 Calcification of the cold-water coral Lophelia pertusa under ambient and reduced pH.\n",
      "Next child: q\n"
     ]
    }
   ],
   "source": [
    "# 9 Story creator\n",
    "import time\n",
    "\n",
    "sentence = sentences[random.randint(0,len(sentences))]\n",
    "root_node = LabSentTreeNode(sentence)\n",
    "actual_node = root_node\n",
    "\n",
    "while actual_node:\n",
    "    clear_output()\n",
    "    log_json(root_node)\n",
    "    log_story(root_node)\n",
    "    print '//////'\n",
    "    print nice_print_labSen(actual_node.sentence)\n",
    "    print '//////'\n",
    "    actual_node.print_options()\n",
    "    time.sleep(1)\n",
    "    actual_node = actual_node.select_child()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The fundamental feature of this network design was neutrality among packets.\n",
      "The design was based on the metastable aggregation of architecture and information.\n",
      "Because the GNU GPL won ’t let them do that.\n",
      ">>>\n",
      "{'index': 4213497, 'children': [{'index': 3851251, 'children': [{'index': 3564378, 'children': [], 'sentence': 'Because the GNU GPL won \\xe2\\x80\\x99t let them do that.'}], 'sentence': 'The design was based on the metastable aggregation of architecture and information.'}], 'sentence': 'The fundamental feature of this network design was neutrality among packets.'}\n"
     ]
    }
   ],
   "source": [
    "print_story(root_node)\n",
    "print '>>>'\n",
    "print root_node.toJSON()\n",
    "#import json\n",
    "#print json.dumps(root_node.toJSON(),indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
