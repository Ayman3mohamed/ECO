{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# install nltk, gensim and keep all texts in the text folder (or link)\n",
    "# creating line-sentences for gensim.word2vec mode with nltk\n",
    "import os\n",
    "import nltk\n",
    "import lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# prepare the text\n",
    "file_path = 'text/v4_combined.txt' # 'text/lucien_sfez.txt' \n",
    "lines = lib.line_sentences(file_path)\n",
    "sentences = lib.sentences_word_tokenized(lines)\n",
    "\n",
    "def print_lines():\n",
    "    for line in lines:\n",
    "        print line, word_tokenize(line)\n",
    "        \n",
    "def print_sentences():\n",
    "    for sentence in sentences:\n",
    "        print sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# build & save the model\n",
    "import gensim\n",
    "import math\n",
    "\n",
    "#model.build_vocab(sentences)\n",
    "model = gensim.models.Word2Vec(sentences, window = 7, workers=8)\n",
    "#model.save()\n",
    "model.init_sims(replace=True)\n",
    "print model\n",
    "print 'model memory size, mb:', model.estimate_memory()['total']/(math.pow(1024,2))\n",
    "model.save('v4_combined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Sentiment analysis of the whole text file\n",
    "# plot, dumping and print of top, worst n senteces\n",
    "\n",
    "from textblob import TextBlob\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "raw = unicode(open(file_path).read(), errors='replace')\n",
    "\n",
    "blob = TextBlob(raw)\n",
    "\n",
    "sentiments = []\n",
    "c = 0\n",
    "for sentence in blob.sentences:\n",
    "    sentiments.append([sentence.sentiment.polarity,c])\n",
    "    #print c,sentence\n",
    "    c += 1\n",
    "\n",
    "\n",
    "sen_sorted_indexed = sorted(sentiments, key= lambda s : s[0])\n",
    "sen_sorted =map(lambda s : s[0],sen_sorted_indexed)\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=[30, 10])\n",
    "plt.plot(sen_sorted)\n",
    "plt.show()\n",
    "\n",
    "dump_file = open('v4_combined_after_retune_sentiment_ranking.json','w')\n",
    "c = 0\n",
    "top_worst_n =10\n",
    "for sen in sen_sorted_indexed:\n",
    "    dump_file.write(json.dumps({'sen':sen,'text':blob.sentences[int(sen[1])].string}))\n",
    "    if c < top_worst_n or c >= len(sen_sorted_indexed) - top_worst_n:\n",
    "        print sen\n",
    "        print blob.sentences[int(sen[1])]\n",
    "    c += 1\n",
    "dump_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk import Text\n",
    "import lib\n",
    "cool_words = []\n",
    "\n",
    "text = Text(lib.word_tokenize(unicode(open(file_path).read(), errors='replace')))\n",
    "\n",
    "for word in model.vocab:  \n",
    "\n",
    "    w_tag = lib.tag(word)\n",
    "    #print word, w_tag[1]\n",
    "    if w_tag[1] in ['NN','VB',\"VBG\",'RB','NNS','ADJ','ADV','ADP']:\n",
    "        cool_words.append(word)\n",
    "#         text.concordance(word)\n",
    "        # #nltk.help.upenn_tagset(w_tag[1])\n",
    "    \n",
    "print len(cool_words), 'nice words'\n",
    "\n",
    "#  djust do that for up to 20 words\n",
    "# lib.scaled_dispersion_plot(text, cool_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print all (noun)words in the vocabulary and their n most similar words\n",
    "for w in cool_words:\n",
    "    if lib.tag(w)[1] == 'NN':\n",
    "        print w #, lib.tag(w)[1], lib.tag(w)[1] == \"NN\"\n",
    "        lib.word_similar_cosmul_p(model, w,topn=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# rest is not interesting/ running\n",
    "\n",
    "# print sentences[0][0]\n",
    "# print map(lambda w : w.encode('ascii',errors='ignore'),sentences[0])\n",
    "# grammar = nltk.CFG.fromstring(sentences[0])\n",
    "# parser = nltk.ChartParser(grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentence = word_tokenize('this is a great tea, which you made by your own')\n",
    "tagged = nltk.pos_tag(sentence)\n",
    "#print tagged\n",
    "entities = nltk.chunk.ne_chunk(tagged)\n",
    "print entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import treebank\n",
    "from nltk.grammar import CFG, Nonterminal\n",
    "\n",
    "tbank_productions = set(production for sent in treebank.parsed_sents()\n",
    "                        for production in sent.productions())\n",
    "tbank_grammar = CFG(Nonterminal('S'), list(tbank_productions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentence = word_tokenize('this is a great tea, which you made by your own')\n",
    "parser = nltk.parse.EarleyChartParser(tbank_grammar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print parser.parse(tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
