{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from random import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Library Gensim (Word2Vec examples)\n",
    "### LOAD GOOGLE WORD2VEC... takes a few minutes\n",
    "from gensim import models\n",
    "# Load google's word2vec model\n",
    "# languages\n",
    "english = 'models/GoogleNews-vectors-negative300.bin.gz'\n",
    "spanish = 'models/SBW-vectors-300-min5.bin.gz'\n",
    "# load\n",
    "model = models.Word2Vec.load_word2vec_format(english, binary=True)\n",
    "model.init_sims(replace=True) # save memory\n",
    "print 'model memory size, gb:', model.estimate_memory()['total']/(math.pow(1024,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some helper functions that print and return an word arithmetic for:\n",
    "- equation (classic similarity)\n",
    "- equation (cosmul similarity)\n",
    "- word (cosmul similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# simple utility functions for printing\n",
    "def print_similarities(similarity_list):\n",
    "    for similarity in similarity_list:\n",
    "        print similarity[0].ljust(18),similarity[1]\n",
    "        \n",
    "def similarities_p(pos=[],neg=[],topn=10,doPrint = True):\n",
    "    if doPrint: \n",
    "        print \"pos:\",pos,\"neg:\",neg\n",
    "    similarities = model.most_similar(pos,neg,topn)\n",
    "    if doPrint: print_similarities(similarities)\n",
    "    return similarities\n",
    "    \n",
    "def most_similar_cosmul_p(pos=[],neg=[],topn=10, doPrint = True):\n",
    "    if doPrint: print \"pos:\",pos,\"neg:\",neg\n",
    "    similarities = model.most_similar_cosmul(pos,neg,topn)\n",
    "    if doPrint: print_similarities(similarities)    \n",
    "    return similarities\n",
    "\n",
    "def word_similar_cosmul_p(word,topn=10, doPrint = True):\n",
    "    if doPrint: print \"word:\",word\n",
    "    similarities = model.most_similar_cosmul([word],[],topn)\n",
    "    if doPrint: print_similarities(similarities)    \n",
    "    return similarities    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model['woman']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "most_similar_cosmul_p(['Spain','Berlin'],['Germany'],10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# DEMO\n",
    "\n",
    "# 1 word arithmetic\n",
    "#model.most_similar(positive=[\"woman\",'girl']) # gunshot?\n",
    "print \"WORD ARITHMETIC\"\n",
    "model.most_similar(positive=[\"man\"]) \n",
    "print model.most_similar(positive=[\"man\",'boy']) \n",
    "# our helper fcts\n",
    "similarities_and_p(['Germany'],['Spain'],topn=5)\n",
    "most_similar_cosmul_p(['Germany'],['Spain'],topn=5)\n",
    "# 2 similarity\n",
    "print \"\\nSIMILARITY\"\n",
    "w1 = 'woman'\n",
    "w2 = 'man'\n",
    "print model.similarity(w1,w2)\n",
    "\n",
    "# 4 non-matching\n",
    "print \"\\nNON-MATCHING WORD\"\n",
    "print model.doesnt_match(\"breakfast cereal dinner lunch\".split())\n",
    "\n",
    "# 5 feature vector\n",
    "vector = model['computer']\n",
    "#print vector\n",
    "\n",
    "# 6 similar by vector\n",
    "vector[np.random.randint(0,300)] += random() * 0.5 - 0.05\n",
    "\n",
    "print model.similar_by_vector(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 'of' is not in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#text1.concordance(\"monstrous\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "b = model['o']\n",
    "#print len(b)\n",
    "#print b\n",
    "print np.linalg.norm(b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Library TextBlob\n",
    "import textblob\n",
    "# READ A TEXT\n",
    "from textblob import TextBlob\n",
    "book = open('../sci-fi-book.txt','r').read()\n",
    "book_blob = TextBlob(book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tag(word):\n",
    "    return TextBlob(word).tags[0]\n",
    "#print tag('win')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"TAGS (grammar tree):\"\n",
    "blob_tags = book_blob.tags\n",
    "print blob_tags\n",
    "\n",
    "print 'NOUN PHRASES'\n",
    "blob_noun_phrases = book_blob.noun_phrases\n",
    "print blob_noun_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'GET VERBS'\n",
    "\n",
    "def get_tag(tags, query_tag):\n",
    "    result = []\n",
    "    for tag in tags:\n",
    "        if tag[1] == query_tag:\n",
    "            result.append(tag)\n",
    "    return result\n",
    "\n",
    "#print get_tag(blob_tags,'VBN')\n",
    "\n",
    "#print book_blob.sentences\n",
    "\n",
    "print \"SENTENCE:\"\n",
    "sentence = book_blob.sentences[np.random.randint(0,len(book_blob.sentences))]\n",
    "print sentence\n",
    "print 'SENTIMENT'\n",
    "print(sentence.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"SOME NLTK\"\n",
    "from nltk.corpus import treebank\n",
    "import nltk\n",
    "\n",
    "book_nltk_text = nltk.Text(book)\n",
    "print book\n",
    "\n",
    "print '\\n',sentence\n",
    "words = sentence.words\n",
    "print words\n",
    "# not working\n",
    "#treebank.parsed_sents(sentence)\n",
    "print sentence.pos_tags\n",
    "nnps = get_tag(sentence.pos_tags,'NNP')\n",
    "\n",
    "#for tree in parser.parse(words):\n",
    "print nnps[0][0]\n",
    "print book_nltk_text.concordance('yes')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word = 'angry'\n",
    "print word,':'\n",
    "print 'similars:'\n",
    "p_similarities(model.most_similar([word],topn=20))\n",
    "start_word = textblob.Word(word)\n",
    "if len(start_word.synsets) != 0:\n",
    "    print('synsets: ' + str(start_word.synsets))\n",
    "    print('definitions: ' + str(start_word.definitions))\n",
    "    synset_index = 0\n",
    "    synset = start_word.synsets[synset_index]\n",
    "    print('lemma_names',synset.lemmas())\n",
    "    print('hypernyms:',synset.hypernyms())\n",
    "    print('hyponyms:',synset.hyponyms())\n",
    "    print('holonyms: ' + str(synset.member_holonyms()))\n",
    "    print('meronyms: ' + str(synset.part_meronyms()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEMO\n",
    "use nltk std chatbots to get an answer\n",
    "then replace some words that by similar or with more positive sentiment\n",
    "display old and new text with color showing the change. \n",
    "black: same\n",
    "green: similar\n",
    "red: higher sentiment\n",
    "\n",
    "TODO: find words that indicate in which conceptual topic the sentence is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.chat import eliza, iesha, rude,suntsu\n",
    "from textblob import TextBlob\n",
    "\n",
    "#eliza.demo()\n",
    "sentence = 'how is it that all birds are gay'\n",
    "eli = eliza.eliza_chatbot\n",
    "print 'eli',eli.respond(sentence)\n",
    "\n",
    "print rude.rude_chatbot.respond(sentence)\n",
    "print iesha.iesha_chatbot.respond(sentence)\n",
    "print suntsu.suntsu_chatbot.respond(sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Take the suntsu response and change all words that have > .85 similarity\n",
    "from IPython.core.display import display, HTML\n",
    "#import progressbar\n",
    "response = suntsu.suntsu_chatbot.respond('how is it that all birds are gay')\n",
    "\n",
    "suntsu_response_blob = TextBlob(response)\n",
    "print suntsu_response_blob\n",
    "suntsu_words = suntsu_response_blob.words\n",
    "print suntsu_response_blob.sentiment\n",
    "reconfig = []\n",
    "reconfig_how = []\n",
    "i = 0 \n",
    "#bar = progressbar.ProgressBar(max_value=len(suntsu_words),redirect_stdout=True)\n",
    "\n",
    "for word in suntsu_response_blob.words:\n",
    "    if word in model:\n",
    "        similar = most_similar_cosmul_p(word,doPrint = False)\n",
    "        suntsu_response_blob.words[i] = similar[0][0]    \n",
    "        positiver = most_similar_cosmul_p([word,'king'],topn = 1,doPrint=False)[0][0]\n",
    "        print word,similar[0], positiver\n",
    "        #if tag(positiver) == tag(word):\n",
    "        if model.similarity(positiver,word) > 0.7:\n",
    "            reconfig.append(\" \".join(positiver.split(\"_\")))\n",
    "            reconfig_how.append(1)\n",
    "        elif similar[0][1] > 0.85:\n",
    "            reconfig.append(\" \".join(similar[0][0].split(\"_\")))\n",
    "            reconfig_how.append(2)\n",
    "        else:\n",
    "            reconfig.append(word)\n",
    "            reconfig_how.append(0)\n",
    "        print '>>>',reconfig[-1],reconfig_how[-1]\n",
    "    i += 1\n",
    "retune = TextBlob(\" \".join(reconfig))\n",
    "print retune\n",
    "print retune.sentiment\n",
    "\n",
    "i = 0 \n",
    "retune_html = ''\n",
    "span_temp = '<span style=\"color:z;\">x </span>'\n",
    "for w in reconfig:\n",
    "    print suntsu_response_blob.words[i],w,reconfig_how[i]\n",
    "    if reconfig_how[i] == 0:\n",
    "        retune_html +=  span_temp.replace('z','black').replace('x',w)\n",
    "    elif reconfig_how[i] == 1:\n",
    "        retune_html +=  span_temp.replace('z','red').replace('x',w)\n",
    "    else:\n",
    "        retune_html +=  span_temp.replace('z','green').replace('x',w)\n",
    "    #print retune_html\n",
    "    i += 1\n",
    "\n",
    "display(HTML('<h1>'+response+'</h1><div>Sentiment:'+str(suntsu_response_blob.sentiment)+'</div>'))\n",
    "display(HTML('<h1>'+retune_html+'</h1><div>Sentiment:'+str(retune.sentiment)+'</div>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#print len(wiki.words)   \n",
    "#print wiki.words\n",
    "#print wiki.tags\n",
    "#noun_phrases = wiki.noun_phrases\n",
    "#print noun_phrases\n",
    "testimonial = TextBlob(\"Textblob is amazingly simple to use. What great fun!\")\n",
    "print testimonial.sentiment\n",
    "testimonial.sentiment.polarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk import Text\n",
    "#print book\n",
    "book_Text = Text(book)\n",
    "print book_Text\n",
    "#book_Text.concordance(\"l\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for np in noun_phrases:\n",
    "    print np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.most_similar(positive=['england', 'paris'], negative=['france'])\n",
    "model.most_similar(positive=['hate',], negative=['love'])\n",
    "model.most_similar(positive=['love',], negative=['hate'])\n",
    "\n",
    "synset.lemmas()\n",
    "\n",
    "#extension from love\n",
    "#tell a story with code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
